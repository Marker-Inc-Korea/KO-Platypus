# KO-Platypus (Ko-Platyü•Æ)
![KO-platypus](./KO_platypus.png)
<div align='center'>
<strong>Korean-Open-platypus Îç∞Ïù¥ÌÑ∞ÏÖãÏùÑ ÌôúÏö©ÌïòÏó¨ llama-2-koÎ•º fine-tuningÌïú Korean-Platypus model</strong> 
<br></br>

**KoT-Platypus2-13Bü•Æ:** [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/kyujinpy/KoT-platypus2-13B) ![im](https://img.shields.io/badge/%F0%9F%A4%97_Ranked_%231-Open_Ko_LLM_Leaderboard-orange?link=https%3A%2F%2Fhuggingface.co%2Fspaces%2Fupstage%2Fopen-ko-llm-leaderboard)    
**KO-Platypus2-13Bü•Æ:** [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/kyujinpy/KO-Platypus2-13B) ![im](https://img.shields.io/badge/%F0%9F%A4%97_Ranked_%232-Open_Ko_LLM_Leaderboard-orange?link=https%3A%2F%2Fhuggingface.co%2Fspaces%2Fupstage%2Fopen-ko-llm-leaderboard)    
**CoTy-platypus-koü•Æ:** [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/MarkrAI/kyujin-CoTy-platypus-ko-12.8b) ![im](https://img.shields.io/badge/%F0%9F%A4%97_Ranked_%235-Open_Ko_LLM_Leaderboard-orange?link=https%3A%2F%2Fhuggingface.co%2Fspaces%2Fupstage%2Fopen-ko-llm-leaderboard)    
**KoT-platypus2-7Bü•Æ:** [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/kyujinpy/KoT-platypus2-7B)  
**KO-Platypus2-7Bü•Æ:** [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/kyujinpy/KO-Platypus2-7B-ex)  
**Poly-platypus-koü•Æ:** [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/MarkrAI/kyujin-Poly-platypus-ko-12.8b)  
  
**KOpen-Platypusü•Æ:** [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/datasets/kyujinpy/KOpen-platypus)   
  
---
</div>
  
# Introduction
- ÏµúÍ∑º **llama-2** Îì±Ïû•ÏúºÎ°ú LLM Î∂ÑÏïºÍ∞Ä Îã§Ïãú ÌôúÎ∞úÌï¥ÏßÄÎäî Í∞ÄÏö¥Îç∞, **Open-Platypus** Îç∞Ïù¥ÌÑ∞ÏÖã ÌôúÏö©ÌïòÏó¨ llama-2Î•º fine-tuningÌïú **Platpyus** Î™®Îç∏Ïù¥ Îì±Ïû•ÌïòÏòÄÏäµÎãàÎã§!ü§ó
- ÌïòÏßÄÎßå Open-Platypus Îç∞Ïù¥ÌÑ∞ÏÖãÏùÄ ÎåÄÎ∂ÄÎ∂Ñ ÏòÅÏñ¥Î°úÎßå Íµ¨ÏÑ±ÎêòÏñ¥ ÏûàÍ∏∞ ÎïåÎ¨∏Ïóê ÌïúÍµ≠Ïñ¥Ïóê Ï†ëÎ™©ÌïòÍ∏∞ÏóêÎäî ÌïúÍ≥ÑÍ∞Ä ÏûàÏóàÏäµÎãàÎã§.
  
- Ïù¥Í≤ÉÏùÑ ÎèôÍ∏∞Î∂ÄÏó¨Î°ú ÏÇºÏïÑÏÑú, ÌïúÍµ≠Ïñ¥ Í∏∞Î∞òÏùò Open-Platypus Îç∞Ïù¥ÌÑ∞ÏÖãÏùÑ Ï†úÏûëÌïú ÌõÑ, **Ko-Platypus**Î•º ÎßåÎì§Í∏∞Î°ú Í≥ÑÌöçÌïòÏòÄÏäµÎãàÎã§!üôÇüôÇ
- Open-PlatypusÎ•º DeepL Pro APIÎ•º ÌôúÏö©ÌïòÏó¨ Î≤àÏó≠ÏùÑ ÏßÑÌñâÌïú ÌõÑ, ÏïΩ 25,000Í∞úÏùò Îç∞Ïù¥ÌÑ∞Î•º ÏàòÏûëÏóÖÏúºÎ°ú Ï≤¥ÌÅ¨ÌïòÏòÄÍ≥† ÏïΩ 144ÏãúÍ∞Ñ Ï†ïÎèÑ ÏÜåÏöîÌïòÏó¨ÏÑú Î≤àÏó≠ Ïò§Î•òÎ•º ÎåÄÎ∂ÄÎ∂Ñ Í≥†Ï≥§ÏäµÎãàÎã§üò≠üò≠
- Ïù¥Î†áÍ≤å ÎßåÎì§Ïñ¥ÏßÑ **ü•ÆKOpen-Platypusü•Æ** Îç∞Ïù¥ÌÑ∞ÏÖãÏùÑ ÌôúÏö©ÌïòÏó¨ beomiÎãòÏùò **llama-2-ko** Î™®Îç∏ÏùÑ fine-tuning ÌïòÏòÄÏäµÎãàÎã§.
  
- Í≤∞Í≥ºÏ†ÅÏúºÎ°ú **Ko-Platypus2-7B-EX** Î™®Îç∏ÏùÑ ÎßåÎì§Í≤å ÎêòÏóàÍ≥†‚úå, ÏÑ±Îä•ÌèâÍ∞ÄÎ•º ÏúÑÌï¥ Polyglot-KoÏôÄ llama-2-ko Î™®Îç∏Í≥º ÎπÑÍµêÎ•º ÏßÑÌñâÌñàÏäµÎãàÎã§.üôÇüôÉ
- Î≥∏ Ïó∞Íµ¨Îäî (Ï£º)ÎßàÏª§ÏôÄ (Ï£º)ÎØ∏ÎîîÏñ¥Í∑∏Î£πÏÇ¨ÎûåÍ≥ºÏà≤Ïùò Ïò§ÌîàÏÜåÏä§ LLM Ïó∞Íµ¨ Ïª®ÏÜåÏãúÏóÑÏóêÏÑú ÏßÑÌñâÎêòÏóàÏäµÎãàÎã§.

# Model BenchMark(KO-LLM)  
| Model | Average | Ko-ARC | Ko-HellaSwag | Ko-MMLU | Ko-TruthfulQA | Ko-CommonGen V2 | Dataset | Base_model |  
| --- | --- | --- | --- | --- | --- | --- | --- | --- |  
| [KoT-Platypus2-13B](https://huggingface.co/kyujinpy/KoT-platypus2-13B) | 49.55 | 43.69 | 53.05 | 42.29 | 43.34 | 65.38 | [KoCoT](https://huggingface.co/datasets/kyujinpy/KoCoT_2000) | KO-platypus2-13B | 
| [KO-platypus2-13B](https://huggingface.co/kyujinpy/KO-Platypus2-13B) | 47.90 | 44.20 | 54.31 | 42.47 | 44.41 | 54.11 | [KOpen-platyus](https://huggingface.co/datasets/kyujinpy/KOpen-platypus) | ko-en-llama2-13b |  
| [CoTy-platypus-ko-12.8b](https://huggingface.co/MarkrAI/kyujin-CoTy-platypus-ko-12.8b) | 46.44 | 34.98 | 49.11 | 25.68 | 37.59 | 84.86 | [KoCoT](https://huggingface.co/datasets/kyujinpy/KoCoT_2000) | Poly-playtypus-ko-12.8b |  
| [KoT-platypus2-7B](https://huggingface.co/kyujinpy/KoT-platypus2-7B) | 45.62 | 38.05 | 49.63 | 34.68 | 37.69 | 68.08 | [KoCoT](https://huggingface.co/datasets/kyujinpy/KoCoT_2000) | KO-platypus2-7B |  
| [KO-Platypus2-7B](https://huggingface.co/kyujinpy/KO-Platypus2-7B-ex) | 45.41 | 39.08 | 50.86 | 34.60 | 37.94 | 64.55 | [KOpen-platyus](https://huggingface.co/datasets/kyujinpy/KOpen-platypus) | llama-2-ko-7B |  
| [Poly-platypus-ko-12.8b](https://huggingface.co/MarkrAI/kyujin-Poly-platypus-ko-12.8b) | 44.95 | 35.15 | 50.39 | 25.68 | 38.74 | 74.88 | [KOpen-platyus](https://huggingface.co/datasets/kyujinpy/KOpen-platypus) | Polyglot-ko-12.8b |  
| [CoT-llama-2k-7b](https://huggingface.co/kyujinpy/CoT-llama-2k-7b) | 41.54 | 36.77 | 49.38 | 29.80 | 37.76 | 53.99 | [KoCoT](https://huggingface.co/datasets/kyujinpy/KoCoT_2000) | llama-2-ko-7B |  
  
  
# Model Description  
  
### KO-Platypus2-7B-ex
- **llama-2-ko-7BÎ•º fine-tuningÌïú Î™®Îç∏**
- **ü•ÆKO-Platypus2-7B-exü•Æ** Î™®Îç∏ÏùÄ zero-shotÏóêÏÑú llama-2-koÎ≥¥Îã§ ÎÜíÏùÄ ÏÑ±Îä•ÏùÑ Î≥¥Ïó¨Ï£ºÏóàÍ≥†, BoolQÏùò Í≤ΩÏö∞ÏóêÎäî Polyglot-KoÎ≥¥Îã§ ÎÜíÏùÄ ÏÑ±Îä•ÏùÑ Î≥¥Ïó¨Ï£ºÏóàÏäµÎãàÎã§.‚úå‚úå
  
# News
- 2023.10.08
   - CoT Î∞©ÏãùÏúºÎ°ú re-fine-tuningÌïú [KoT-platypus-13Bü§ó](https://huggingface.co/kyujinpy/KoT-platypus2-13B) Model Ï†úÏûë ÏôÑÎ£å.  
   - HuggingFace KO-LLM 1Îì± Îã¨ÏÑ±.

- 2023.10.05
   - [ko-en-llama2-13b](https://huggingface.co/hyunseoki/ko-en-llama2-13b)Î•º Í∏∞Î∞òÏúºÎ°ú Ìïú [Ko-platypus2-13Bü§ó](https://huggingface.co/kyujinpy/KO-Platypus2-13B) Model Ï†úÏûë ÏôÑÎ£å.  
   - HuggingFace KO-LLM 2Îì±(~~1Îì±~~) Îã¨ÏÑ±.

- 2023.10.04
  - CoTÎ∞©ÏãùÏúºÎ°ú Poly-platypus-koÎ•º fine-tuningÌïú [CoTy-platypus-ko-12.8bü§ó](https://github.com/KyujinHan/Poly-platypus-ko) Model Ï†úÏûë ÏôÑÎ£å.
  - HuggingFace KO-LLM 5Îì±(~~2Îì±~~) Îã¨ÏÑ±.

- 2023.10.02
  - Polyglot-koÎ•º Í∏∞Î∞òÏúºÎ°ú ÌïòÏó¨ [Poly-platypus-ko-12.8bü§ó](https://github.com/KyujinHan/Poly-platypus-ko) Model Ï†úÏûë ÏôÑÎ£å.  
  - HuggingFace KO-LLM Î¶¨ÎçîÎ≥¥Îìú ~~4Îì±~~Îã¨ÏÑ±.

- 2023.10.01
  - CoTÎ∞©ÏãùÏúºÎ°ú re-fine-tuningÌïú [KoT-platypus2-7Bü§ó](https://github.com/KyujinHan/KoT-platypus) Model Ï†úÏûë ÏôÑÎ£å. 
  - HuggingFace KO-LLM Î¶¨ÎçîÎ≥¥Îìú ~~5Îì±~~(~~1Îì±~~) Îã¨ÏÑ±. 
  
- 2023.09.29
  - [Ko-platypus2-7Bü§ó](https://huggingface.co/kyujinpy/KO-Platypus2-7B-ex) Model [KO-LLM leaderboardü§ó](https://huggingface.co/spaces/upstage/open-ko-llm-leaderboard)ÏóêÏÑú ~~2Îì±~~(~~1Îì±~~) Îã¨ÏÑ±.
   
# Quick start
```python
### KO-Platy
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

repo = "kyujinpy/KO-Platypus2-7B-ex"
ko_platypus = AutoModelForCausalLM.from_pretrained(
        repo,
        return_dict=True,
        torch_dtype=torch.float16,
        device_map='auto'
)
ko_platypus_tokenizer = AutoTokenizer.from_pretrained(repo)
```
  
# Training 
1. First download the origina repo [Platypus](https://github.com/arielnlee/Platypus)
2. ü•ÆRun the fileü•Æ: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1qtGQroKPwGFA1L9b3WGyHC84NDIEs6s_?usp=sharing)
  
>*Note: You must access the original [llama-2](https://huggingface.co/meta-llama/Llama-2-7b).      
>**Note: You must generate your huggingface token. And after login, you can implement this [colab](https://colab.research.google.com/drive/1qtGQroKPwGFA1L9b3WGyHC84NDIEs6s_?usp=sharing).  
>***Note: If you run Platypus in colab, you must use A100 GPU.  

# Datasets
```python
from datasets import load_dataset

# dataset testing
dataset = load_dataset("kyujinpy/KOpen-platypus")
```  
**KOpen-Platypusü•Æ:** [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/datasets/kyujinpy/KOpen-platypus)   
> I think that **KOpen-Platypus** is higher quality korean-translation dataset than just using DeepL. Because I almost check translation-error.  

**Procedure**  
- First, I use [DeepL Pro API](https://www.deepl.com/translator) and [Selenium Code](https://github.com/KyujinHan/Korean_selenium_DeepL).
- Second, checking all data. If there are some errors, I modify translation myself.
*If you want more detail, see below `Post-procesing`.  
  
## Post-processing
![example](./example.png)
I focus about **5 type errors.**  
1. Result of just code  
2. Result of code+explanation   
3. Float missing   
4. Math symbol   
5. Not translation or cut off translation result
  
>*Note: If you want to see more detail example, visit [huggingface](https://huggingface.co/datasets/kyujinpy/KOpen-platypus) or [Ko-Platypus-blog](https://kyujinpy.tistory.com/101).  
  
# Performance(Old_version)
When I evaluated Ko-Platy, I used this [repo](https://github.com/Beomi/ko-lm-evaluation-harness).  
And, implement below code.
```
# In colab,
!python main.py \
    --model gpt2 \ 
    --model_args pretrained=..your_model_name.. \
    --tasks kobest_hellaswag,kobest_copa,kobest_boolq,kobest_sentineg \
    --device cuda:0 \
    --num_fewshot 0 # 5, 10, 25, ...
```
  
### COPA (F1)
| Model | 0-shot | 5-shot | 10-shot | 50-shot |
| --- | --- | --- | --- | --- |
| [Polyglot-ko-1.3b](https://huggingface.co/EleutherAI/polyglot-ko-1.3b) | 0.7196 | 0.7193 | 0.7204 | 0.7206 |
| [Polyglot-ko-3.8b](https://huggingface.co/EleutherAI/polyglot-ko-3.8b) | 0.7595 | 0.7608 | 0.7638 | 0.7788 |
| [Polyglot-ko-5.8b](https://huggingface.co/EleutherAI/polyglot-ko-5.8b) | 0.7745 | 0.7676 | 0.7775 | 0.7887 |
| [Polyglot-ko-12.8b](https://huggingface.co/EleutherAI/polyglot-ko-12.8b) | 0.7937 | 0.8108 | 0.8037 | 0.8369 |
| [Llama-2-Ko-7b 20B](https://huggingface.co/beomi/llama-2-ko-7b) | 0.7388 | 0.7626 | 0.7808 | 0.7979 |
| [Llama-2-Ko-7b 40B](https://huggingface.co/beomi/llama-2-ko-7b) | 0.7436 | 0.7927 | 0.8037 | 0.8259 |  
| **KO-platypus2-7B-EX(ours)** | 0.7509 | 0.7899 | 0.8029 | 0.8290 |   
  
### HellaSwag (F1)
| Model | 0-shot | 5-shot | 10-shot | 50-shot |
| --- | --- | --- | --- | --- |
| [Polyglot-ko-1.3b](https://huggingface.co/EleutherAI/polyglot-ko-1.3b) | 0.5247 | 0.5260 | 0.5278 | 0.5427 |
| [Polyglot-ko-3.8b](https://huggingface.co/EleutherAI/polyglot-ko-3.8b) | 0.5707 | 0.5830 | 0.5670 | 0.5787 |
| [Polyglot-ko-5.8b](https://huggingface.co/EleutherAI/polyglot-ko-5.8b) | 0.5976 | 0.5998 | 0.5979 | 0.6208 |
| [Polyglot-ko-12.8b](https://huggingface.co/EleutherAI/polyglot-ko-12.8b) | 0.5954 | 0.6306 | 0.6098 | 0.6118 |
| [Llama-2-Ko-7b 20B](https://huggingface.co/beomi/llama-2-ko-7b) | 0.4518 | 0.4668 | 0.4726 | 0.4828 |
| [Llama-2-Ko-7b 40B](https://huggingface.co/beomi/llama-2-ko-7b) | 0.4562 | 0.4657 | 0.4698 | 0.4774 |   
| **KO-platypus2-7B-EX(ours)** | 0.4571 | 0.4461 | 0.4371 | 0.4525 |   
  
### BoolQ (F1)
| Model | 0-shot | 5-shot | 10-shot | 50-shot |
| --- | --- | --- | --- | --- |
| [Polyglot-ko-1.3b](https://huggingface.co/EleutherAI/polyglot-ko-1.3b) | 0.3552 | 0.4751 | 0.4109 | 0.4038 |
| [Polyglot-ko-3.8b](https://huggingface.co/EleutherAI/polyglot-ko-3.8b) | 0.4320 | 0.5263 | 0.4930 | 0.4038 |
| [Polyglot-ko-5.8b](https://huggingface.co/EleutherAI/polyglot-ko-5.8b) | 0.4356 | 0.5698 | 0.5187 | 0.5236 |
| [Polyglot-ko-12.8b](https://huggingface.co/EleutherAI/polyglot-ko-12.8b) | 0.4818 | 0.6041 | 0.6289 | 0.6448 |
| [Llama-2-Ko-7b 20B](https://huggingface.co/beomi/llama-2-ko-7b) | 0.3607 | 0.6797 | 0.6801 | 0.6622 |
| [Llama-2-Ko-7b 40B](https://huggingface.co/beomi/llama-2-ko-7b) | 0.5786 | 0.6977 | 0.7084 | 0.7144 |  
| **KO-platypus2-7B-EX(ours)** | 0.6028 | 0.6979 | 0.7016 | 0.6988 |  
  
### SentiNeg (F1)
| Model | 0-shot | 5-shot | 10-shot | 50-shot |
| --- | --- | --- | --- | --- |
| [Polyglot-ko-1.3b](https://huggingface.co/EleutherAI/polyglot-ko-1.3b) | 0.6790 | 0.6257 | 0.5514 | 0.7851 |
| [Polyglot-ko-3.8b](https://huggingface.co/EleutherAI/polyglot-ko-3.8b) | 0.4858 | 0.7950 | 0.7320 | 0.7851 |
| [Polyglot-ko-5.8b](https://huggingface.co/EleutherAI/polyglot-ko-5.8b) | 0.3394 | 0.8841 | 0.8808 | 0.9521 |
| [Polyglot-ko-12.8b](https://huggingface.co/EleutherAI/polyglot-ko-12.8b) | 0.9117 | 0.9015 | 0.9345 | 0.9723 |
| [Llama-2-Ko-7b 20B](https://huggingface.co/beomi/llama-2-ko-7b) | 0.4855 | 0.8295 | 0.8711 | 0.8513 |
| [Llama-2-Ko-7b 40B](https://huggingface.co/beomi/llama-2-ko-7b) | 0.4594 | 0.7611 | 0.7276 | 0.9370 |  
| **KO-platypus2-7B-EX(ours)** | 0.5821 | 0.7653 | 0.7991 | 0.8643 |  
   
# References
[Kopen-Platypusü•Æ](https://huggingface.co/datasets/kyujinpy/KOpen-platypus)   
[KO-Platypus2-7B-exü•Æ](https://huggingface.co/kyujinpy/KO-Platypus2-7B-ex)  
[KO-Platypus2-13Bü•Æ](https://huggingface.co/kyujinpy/KO-Platypus2-13B)  
[Platypus](https://github.com/arielnlee/Platypus)  
[llama-2](https://huggingface.co/meta-llama/Llama-2-7b)  
[llama-2-ko](https://huggingface.co/beomi/llama-2-ko-7b)  
[ko-en-llama2](https://huggingface.co/hyunseoki/ko-en-llama2-13b)  
[ko-lm-evaluation-harness](https://github.com/Beomi/ko-lm-evaluation-harness)   
  
# TODO
- [x] Make KO-Platypus-7B-EX  
- [x] Share huggingface repo
- [x] Share evaluation results
- [x] Share sample code

## Additional info about image
I made the image, inspired by [Platypus-LLM](https://github.com/arielnlee/Platypus).  
I used [Playground AI](https://playgroundai.com/), then applying prompt engineering. (For example, img2img, guidance etc...)  

When I made `Ko-Platy` image, I use prompt like below.
```
Prompt: 'Platypus wears a pretty traditional Korean clothes with ÌïúÍµ≠Ïñ¥ Ï±Ö'
Guidance: 10
Quality: 70~100
img2img: 'Platypus.png'
Model: SDXL
```  
